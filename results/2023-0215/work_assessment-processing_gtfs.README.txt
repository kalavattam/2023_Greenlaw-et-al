
#  work_assessment-processing_gtfs.README.txt
#  KA
#  2023-0410


#  ------------------------------------
#  I. How I called gffread
#+ 
#+ A. Base
gffread \
    -v \
    -g "${fasta_g}" \
    -i 1000 \
    -Z \
    -M -K -Q \
    -F -N -P \
    --force-exons --gene2exon \
    -o "${out}" \
    <(awk -F '\t' 'BEGIN {OFS = FS} { gsub(/chr/, "", $1); gsub(/M/, "Mito", $1); print }' "${in}") \
         > >(tee -a "${err_out%.}.stdout.txt") \
        2> >(tee -a "${err_out%.}.stderr.txt")

#+ B. Intron-filtering only
#+ 
#+ No collapsing, merging with these files; only filtering to exclude exonic features with introns greater than 1000 bp in length
gffread \
    -v -O \
    -i 1000 \
    -o "${out/.gff3/-intron-filtering-only.gff3}" \
    <(awk -F '\t' 'BEGIN {OFS = FS} { gsub(/chr/, "", $1); gsub(/M/, "Mito", $1); print }' "${in}") \
         > >(tee -a "${err_out%.}-intron-filtering-only.stdout.txt") \
        2> >(tee -a "${err_out%.}-intron-filtering-only.stderr.txt")

#+ C. Meaning of parameters
#+ 
#+ 1. Base
-v expose (warn about) duplicate transcript IDs and other potential problems with the given GFF/GTF records
-g full path to a fasta file with the genomic sequences for all input mappings (one per genomic sequence, with file names matching sequence names) (#NOTE i.e., the fasta file output from running Trinity in genome-guided mode)
-i discard transcripts having an intron larger than 1000 bp
-Z merge very close exons into a single exon (when intron size<4)
-M cluster the input transcripts into loci, discarding "redundant" transcripts (those with the same exact introns and fully contained or equal boundaries)
-K for the -M option, also discard as redundant the shorter, fully contained transcripts (intron chains matching a part of the container)
-Q for the -M option, no longer require boundary containment when assessing redundancy (can be combined with -K); only introns have to match for multi-exon transcripts, and >=80% overlap for single-exon transcripts
-F keep all GFF attributes (for non-exon features)
-N discard multi-exon mRNAs that have any intron with a non-canonical splice site consensus (i.e., not GT-AG, GC-AG or AT-AC)
-P add transcript level GFF attributes about the coding status of each transcript, including partialness or in-frame stop codons (requires -g)
--force-exons make sure that the lowest level GFF features are considered "exon" features (#NOTE This is standard in gff3 and gtf files)
-o write the output records into <outfile> instead of stdout

#+ 2. Intron-filtering only
-v expose (warn about) duplicate transcript IDs and other potential problems with the given GFF/GTF records
-O process other non-transcript GFF records (by default non-transcript records are ignored) (#NOTE This keeps 'gene' features (output by gmap) in the gff3/gtf, although 'gene' is exactly the same as 'mRNA' as output by gmap)
-i discard transcripts having an intron larger than 1000 bp
-o write the output records into <outfile> instead of stdout


#  ------------------------------------
#  II. How I called htseq-count
#+ 
#+ A. locus
#+ 
#+ As a result of calling gffread with the -Z -M -K and -Q arguments, a new feature is added to the gff3/gtf files: "locus"
#+ 
#+ "locus" is a putative parent feature made from collapsing and joining "children" features (hierarchically, mRNA and exon) as described for -Z -M -K and -Q
#+ 
#+ This is an extension of the kind of collapsing performed by gffcompare -C
#+ 
#+ Thus, counts matrices were created with respect to these "locus" features
sbatch \
    --job-name="htseq-count-locus" \
    --nodes=1 \
    --cpus-per-task=8 \
    --error="${err_out}-locus.%A.stderr.txt" \
    --output="${err_out}-locus.%A.stdout.txt" \
    htseq-count \
        --order "pos" \
        --stranded "${hc_strd}" \
        --nonunique "all" \
        --type "locus" \
        --idattr "ID" \
        --nprocesses 8 \
        --counts_output "${out/.tsv/-locus.tsv}" \
        --with-header \
        ${bams[*]} \
        "${in}"

#+ B. mRNA
#+ 
#+ Create the counts matrix by looking at children "mRNA" features rather than parent "locus" features
#+ 
#+ This is the kind of collapsing performed by gffcompare -C
sbatch \
    --job-name="htseq-count-mRNA" \
    --nodes=1 \
    --cpus-per-task=8 \
    --error="${err_out}-mRNA.%A.stderr.txt" \
    --output="${err_out}-mRNA.%A.stdout.txt" \
    htseq-count \
        --order "pos" \
        --stranded "${hc_strd}" \
        --nonunique "all" \
        --type "mRNA" \
        --idattr "ID" \
        --nprocesses 8 \
        --counts_output "${out/.tsv/-mRNA.tsv}" \
        --with-header \
        ${bams[*]} \
        "${in}"

#+ C. exon
#+ 
#+ Create the counts matrix by looking at children "exon" features
sbatch \
    --job-name="htseq-count-exon" \
    --nodes=1 \
    --cpus-per-task=8 \
    --error="${err_out}-exon.%A.stderr.txt" \
    --output="${err_out}-exon.%A.stdout.txt" \
    htseq-count \
        --order "pos" \
        --stranded "${hc_strd}" \
        --nonunique "all" \
        --type "exon" \
        --idattr "Parent" \
        --nprocesses 8 \
        --counts_output "${out/.tsv/-exon.tsv}" \
        --with-header \
        ${bams[*]} \
        "${in}"

#+ D. CDS
#+ 
#+ gffread scans the fastas supplied -g and roughly estimates start and stop codons from the nt sequences; it then adds these CDS estimates to the gff3/gtf files
#+ 
#+ Create the counts matrix by looking at these estimated "CDS" features
sbatch \
    --job-name="htseq-count-CDS" \
    --nodes=1 \
    --cpus-per-task=8 \
    --error="${err_out}-CDS.%A.stderr.txt" \
    --output="${err_out}-CDS.%A.stdout.txt" \
    htseq-count \
        --order "pos" \
        --stranded "${hc_strd}" \
        --nonunique "all" \
        --type "CDS" \
        --idattr "Parent" \
        --nprocesses 8 \
        --counts_output "${out/.tsv/-CDS.tsv}" \
        --with-header \
        ${bams[*]} \
        "${in}"

#+ E. intron-only filtering
#+ 
#+ Create the counts matrix by looking at parent "gene" features from the files output in section "I" subsection "B" above
sbatch \
    --job-name="htseq-count-gene" \
    --nodes=1 \
    --cpus-per-task=8 \
    --error="${err_out}-gene.%A.stderr.txt" \
    --output="${err_out}-gene.%A.stdout.txt" \
    htseq-count \
        --order "pos" \
        --stranded "${hc_strd}" \
        --nonunique "all" \
        --type "gene" \
        --idattr "ID" \
        --nprocesses 8 \
        --counts_output "${out/.tsv/-gene.tsv}" \
        --with-header \
        ${bams[*]} \
        "${in}"


#  ------------------------------------
#  III. How I created the filtered gtfs
#+ 
#+ A. Read in and process gtf/gff3 files (as data frames)
#+ B. Read in and process counts matrices (locus, mRNA, exon, CDS, and intron-only filtering)
#+ C. Categorize putative transcripts/transcript fragments by percentile (from < percentile 5 to < percentile 95 in steps of 5)
#+ D. Subset data frames to retain percentile-filtered IDs (locus, mRNA, exon, CDS, and intron-only filtering)
#+ E. Write out processed gtfs


#  ------------------------------------
#  IV. Copying over files to Alison

```bash
#!/bin/bash

mkdir -p /home/kalavatt/tsukiyamalab/alisong/KA.gtfs_quantile-filtered_Trinity-GG_G1-Q_2023-0410/{gtf-gff3,tsv}
# mkdir: created directory '/home/kalavatt/tsukiyamalab/alisong/KA.gtfs_quantile-filtered_Trinity-GG_G1-Q_2023-0410'
# mkdir: created directory '/home/kalavatt/tsukiyamalab/alisong/KA.gtfs_quantile-filtered_Trinity-GG_G1-Q_2023-0410/gtf-gff3'
# mkdir: created directory '/home/kalavatt/tsukiyamalab/alisong/KA.gtfs_quantile-filtered_Trinity-GG_G1-Q_2023-0410/tsv'

cd /home/kalavatt/tsukiyamalab/kalavatt/2022_transcriptome-construction/results/2023-0215

cp -r \
    outfiles_gtf-gff3/Trinity-GG \
    /home/kalavatt/tsukiyamalab/alisong/KA.gtfs_quantile-filtered_Trinity-GG_G1-Q_2023-0410/gtf-gff3

cp -r \
    outfiles_htseq-count/Trinity-GG \
    /home/kalavatt/tsukiyamalab/alisong/KA.gtfs_quantile-filtered_Trinity-GG_G1-Q_2023-0410/tsv

#  Manually copying in the 'filtered/' subdirectories from local to remote
```
